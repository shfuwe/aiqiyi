{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = ('../data/train_dataset_v2.tsv')\n",
    "script_ids = []\n",
    "scene_nums = []\n",
    "sentence_nums = []\n",
    "ids = []\n",
    "contents = []\n",
    "characters = []\n",
    "emotions = []\n",
    "index = 0\n",
    "with open(file_path,'r',encoding='utf-8') as f:\n",
    "    for line in f.readlines():\n",
    "        if index > 0:\n",
    "            item = line.replace('\\n','').split('\\t')\n",
    "            id,content,character,emotion = item[0],item[1],item[2],item[3]\n",
    "            script_id,scene_num,sentence_num = id.split('_')[0],id.split('_')[1],id.split('_')[3]\n",
    "            script_ids.append(script_id)\n",
    "            scene_nums.append(scene_num)\n",
    "            sentence_nums.append(sentence_num)\n",
    "            ids.append(id)\n",
    "            contents.append(content)\n",
    "            characters.append(character)\n",
    "            emotions.append(emotion)\n",
    "        index += 1\n",
    "def make_sen(sen,char):\n",
    "    test=sen.replace('*',' ')\n",
    "    test=test.replace(char,'*')\n",
    "    return test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "总数： 36782\n",
      "分界： 34900 34527 34314\n",
      "30102 6680\n"
     ]
    }
   ],
   "source": [
    "n=0\n",
    "for i in range(len(script_ids)):\n",
    "    if emotions[i]=='':\n",
    "        continue\n",
    "    n+=1\n",
    "print('总数：',n)\n",
    "\n",
    "n=0\n",
    "a=0\n",
    "b=0\n",
    "for i in range(len(script_ids)):\n",
    "    if emotions[i]=='':\n",
    "        continue\n",
    "    n+=1\n",
    "    if a ==0 and n>36782*0.8:\n",
    "        a=script_ids[n]\n",
    "    if a!=0:\n",
    "        b = script_ids[n]\n",
    "    if b!=a:\n",
    "        break\n",
    "print('分界：',i,script_ids[n],script_ids[n-1])\n",
    "\n",
    "train_x=[]\n",
    "train_y=[]\n",
    "test_x=[]\n",
    "test_y=[]\n",
    "for i in range(len(script_ids)):\n",
    "    if emotions[i]=='':\n",
    "        continue\n",
    "        \n",
    "    if int(script_ids[i])<=34900:\n",
    "        if characters[i]=='':\n",
    "            train_x.append(contents[i])\n",
    "        else:\n",
    "            train_x.append(make_sen(contents[i],characters[i]))\n",
    "        train_y.append([int (ii) for ii in emotions[i].split(',')])\n",
    "    else:\n",
    "        if characters[i]=='':\n",
    "            test_x.append(contents[i])\n",
    "        else:\n",
    "            test_x.append(make_sen(contents[i],characters[i]))\n",
    "        test_y.append([int (ii) for ii in emotions[i].split(',')])\n",
    "        \n",
    "print(len(train_x),len(test_x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                    text               label\n",
      "0               天空下着暴雨，*正在给c1穿雨衣，他自己却只穿着单薄的军装，完全暴露在大雨之中。  [0, 0, 0, 0, 0, 0]\n",
      "1               天空下着暴雨，o2正在给*穿雨衣，他自己却只穿着单薄的军装，完全暴露在大雨之中。  [0, 0, 0, 0, 0, 0]\n",
      "2                            *一手拿着一个行李，一路小跑着把c1带到了文工团门口。  [0, 0, 0, 0, 0, 0]\n",
      "3                            o2一手拿着一个行李，一路小跑着把*带到了文工团门口。  [0, 0, 0, 0, 0, 0]\n",
      "4      *停下来接过c1手里的行李：你妈妈交待我了，等领了军装一定要照张相寄回去，让街坊邻居都知道你...  [0, 0, 0, 0, 0, 0]\n",
      "...                                                  ...                 ...\n",
      "30097                             *：……一个人过日子，日子也就忽然觉得长了。  [0, 0, 0, 0, 0, 2]\n",
      "30098                             邻居*：的确是啊……寂寞了嘛……（说完走了）  [0, 0, 0, 0, 0, 1]\n",
      "30099                                              *：啊……  [0, 0, 0, 0, 0, 2]\n",
      "30100                                *独自眺望大海，不由得深深地叹了口气。  [0, 0, 0, 0, 0, 2]\n",
      "30101                                    *呆呆地眺望着远方的小汽艇——  [0, 0, 0, 0, 0, 2]\n",
      "\n",
      "[30102 rows x 2 columns]\n",
      "                                                   text               label\n",
      "0                            a1、*、h2相邻而坐，面对各自窗口后的白人签证官。  [0, 0, 0, 0, 0, 0]\n",
      "1                            a1、b1、*相邻而坐，面对各自窗口后的白人签证官。  [0, 0, 0, 0, 0, 0]\n",
      "2                         b1胜券在握，h2轻松洒脱，唯独*右手紧握左手，紧张僵硬。  [0, 0, 0, 0, 1, 0]\n",
      "3                         *胜券在握，h2轻松洒脱，唯独a1右手紧握左手，紧张僵硬。  [0, 1, 0, 0, 0, 0]\n",
      "4                         b1胜券在握，*轻松洒脱，唯独a1右手紧握左手，紧张僵硬。  [0, 0, 0, 0, 0, 0]\n",
      "...                                                 ...                 ...\n",
      "6675                                  *的未婚夫手捧大束玫瑰花在寻找*。  [0, 0, 0, 0, 0, 0]\n",
      "6676                 *看看表：过了五分钟。他从口袋里掏出药盒，倒出药：一片，两片，半片。  [0, 3, 0, 0, 0, 0]\n",
      "6677  *转脸朝前走。突然站住了，他看见自己的前妻，c1领着女儿g3站在前面。他过去，三人紧紧拥在一...  [2, 3, 0, 0, 0, 0]\n",
      "6678  b1转脸朝前走。突然站住了，他看见自己的前妻，*领着女儿g3站在前面。他过去，三人紧紧拥在一...  [2, 3, 0, 0, 0, 0]\n",
      "6679  b1转脸朝前走。突然站住了，他看见自己的前妻，c1领着女儿g3站在前面。他过去，三人紧紧拥在...  [0, 0, 0, 0, 0, 0]\n",
      "\n",
      "[6680 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df_train = {\"text\": train_x, \"label\": train_y}\n",
    "df_train = pd.core.frame.DataFrame(df_train)\n",
    "print(df_train)\n",
    "\n",
    "df_test = {\"text\": test_x, \"label\": test_y}\n",
    "df_test = pd.core.frame.DataFrame(df_test)\n",
    "print(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.to_excel(\"../data/df_train.xlsx\")\n",
    "df_test.to_excel(\"../data/df_test.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "# 读数据\n",
    "df_train=pd.read_excel(\"../data/df_train.xlsx\",index_col=0)\n",
    "df_test=pd.read_excel(\"../data/df_test.xlsx\",index_col=0)\n",
    "import ast\n",
    "for i in range(len(df_train)):\n",
    "    df_train.loc[i]['label']=ast.literal_eval(df_train.loc[i]['label'])\n",
    "\n",
    "for i in range(len(df_test)):\n",
    "    df_test.loc[i]['label']=ast.literal_eval(df_test.loc[i]['label'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModel\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-chinese\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print([df_train['text'][i] for i in range(len(df_train))])\n",
    "df_train_text=[df_train['text'][i] for i in range(len(df_train))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['label']=df_train_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = ('../data/test_dataset.tsv')\n",
    "script_ids = []\n",
    "scene_nums = []\n",
    "sentence_nums = []\n",
    "ids = []\n",
    "contents = []\n",
    "characters = []\n",
    "emotions = []\n",
    "index = 0\n",
    "with open(file_path,'r',encoding='utf-8') as f:\n",
    "    for line in f.readlines():\n",
    "        if index > 0:\n",
    "            item = line.replace('\\n','').split('\\t')\n",
    "            id,content,character = item[0],item[1],item[2]\n",
    "            script_id,scene_num,sentence_num = id.split('_')[0],id.split('_')[1],id.split('_')[3]\n",
    "            script_ids.append(script_id)\n",
    "            scene_nums.append(scene_num)\n",
    "            sentence_nums.append(sentence_num)\n",
    "            ids.append(id)\n",
    "            contents.append(content)\n",
    "            characters.append(character)\n",
    "        index += 1\n",
    "def make_sen(sen,char):\n",
    "    test=sen.replace('*',' ')\n",
    "    test=test.replace(char,'*')\n",
    "    return test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21376\n"
     ]
    }
   ],
   "source": [
    "train_x=[]\n",
    "for i in range(len(script_ids)):\n",
    "    if characters[i]=='':\n",
    "        train_x.append(contents[i])\n",
    "    else:\n",
    "        train_x.append(make_sen(contents[i],characters[i]))\n",
    "        \n",
    "        \n",
    "print(len(train_x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def store_list(lsit,text_path):\n",
    "    ff = open(text_path, encoding='utf-8', mode='w')\n",
    "    for line_list in lsit:\n",
    "        ff.write(str(line_list))  # 写入一个新文件中\n",
    "        ff.write(\"\\n\")\n",
    "store_list(train_x,'../data/pre_data.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bs0",
   "language": "python",
   "name": "bs0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
