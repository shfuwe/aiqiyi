{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "ban=0\n",
    "batch_size=16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "device0 = torch.device('cuda:5' if torch.cuda.is_available() else \"cpu\")\n",
    "device1 = torch.device('cuda:5' if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 读数据\n",
    "import pandas as pd\n",
    "df_train=pd.read_excel(\"../data/df_train.xlsx\",index_col=0)\n",
    "df_test=pd.read_excel(\"../data/df_test.xlsx\",index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 30102/30102 [00:02<00:00, 12801.69it/s]\n",
      "100%|██████████| 6680/6680 [00:00<00:00, 11821.40it/s]\n"
     ]
    }
   ],
   "source": [
    "y=[]\n",
    "from tqdm import tqdm\n",
    "for i in tqdm(range(len(df_train))):\n",
    "    if df_train.loc[i]['label']=='[0, 0, 0, 0, 0, 0]':\n",
    "        y.append(0)\n",
    "    else:\n",
    "#         print(df_train.loc[i]['label'])\n",
    "        y.append(1)\n",
    "df_train['label']=y\n",
    "y=[]\n",
    "for i in tqdm(range(len(df_test))):\n",
    "    if df_test.loc[i]['label']=='[0, 0, 0, 0, 0, 0]':\n",
    "        y.append(0)\n",
    "    else:\n",
    "#         print(df_test.loc[i]['label'])\n",
    "        y.append(1)\n",
    "df_test['label']=y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_text=[df_train['text'][i].replace('*','##char##') for i in range(len(df_train))]\n",
    "df_test_text=[df_test['text'][i].replace('*','##char##') for i in range(len(df_test))]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['text']=df_train_text\n",
    "df_test['text']=df_test_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModel\n",
    "added_token=['##char##']\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-chinese\",additional_special_tokens=added_token)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "text2id_train = tokenizer(\n",
    "        df_train_text, max_length=100, padding='max_length', truncation=True, return_tensors=\"pt\"\n",
    "    )\n",
    "input_ids_train=text2id_train[\"input_ids\"]\n",
    "mask_train=text2id_train[\"attention_mask\"]\n",
    "\n",
    "text2id_test = tokenizer(\n",
    "        df_test_text, max_length=100, padding='max_length', truncation=True, return_tensors=\"pt\"\n",
    "    )\n",
    "input_ids_test=text2id_test[\"input_ids\"]\n",
    "mask_test=text2id_test[\"attention_mask\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['input_ids']=input_ids_train.tolist()\n",
    "df_train['mask']=mask_train.tolist()\n",
    "\n",
    "df_test['input_ids']=input_ids_test.tolist()\n",
    "df_test['mask']=mask_test.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "class SentimentDataset(Dataset):\n",
    "    def __init__(self,df):\n",
    "        self.dataset = df\n",
    "    def __len__(self):\n",
    "        return len(self.dataset)\n",
    "    def __getitem__(self, idx):\n",
    "        text = self.dataset.loc[idx, \"text\"]\n",
    "        label = self.dataset.loc[idx, \"label\"]\n",
    "#         print(label)\n",
    "        input_ids = self.dataset.loc[idx, \"input_ids\"]\n",
    "        mask = self.dataset.loc[idx, \"mask\"]\n",
    "        sample = {\"text\": text, \"label\": label,\"input_ids\":input_ids,\"mask\":mask}\n",
    "        # print(sample)\n",
    "        return sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<torch.utils.data.dataloader.DataLoader object at 0x7f573da444d0>\n",
      "<torch.utils.data.dataloader.DataLoader object at 0x7f573da44790>\n"
     ]
    }
   ],
   "source": [
    "#按batch_size分\n",
    "from torch.utils.data import DataLoader,TensorDataset\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    SentimentDataset(df_train), \n",
    "    batch_size=batch_size, \n",
    "    shuffle=True, \n",
    "    num_workers=0\n",
    ")\n",
    "print(train_loader)\n",
    "\n",
    "test_loader = DataLoader(\n",
    "    SentimentDataset(df_test), \n",
    "    batch_size=batch_size, \n",
    "    shuffle=False, \n",
    "    num_workers=0\n",
    ")\n",
    "print(test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21128"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer('##char##')['input_ids'][1]#21128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1, 2, 3],\n",
      "        [3, 2, 2],\n",
      "        [3, 1, 1]])\n",
      "tensor([[0, 1, 0],\n",
      "        [0, 1, 1],\n",
      "        [0, 0, 0]], dtype=torch.int32)\n",
      "tensor([1, 2, 0])\n"
     ]
    }
   ],
   "source": [
    "a=torch.tensor([[1,2,3],[3,2,2],[3,1,1]])\n",
    "print(a)\n",
    "b=torch.stack([(i==2).int() for i in a])\n",
    "print(b)\n",
    "c=torch.tensor([i.sum() for i in b])\n",
    "print(c)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModel\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class fn2_cls(nn.Module):\n",
    "    def __init__(self,device):\n",
    "        super(fn2_cls, self).__init__()\n",
    "        self.model = AutoModel.from_pretrained(\"bert-base-chinese\")\n",
    "        self.model.resize_token_embeddings(len(tokenizer))##############\n",
    "        self.model.to(device)\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "        self.l1 = nn.Linear(768, 1)\n",
    "    def forward(self, x, attention_mask=None):\n",
    "        target_num=tokenizer('##char##')['input_ids'][1]#21128\n",
    "        x_pos=torch.stack([(i==target_num).int() for i in x])#b*100\n",
    "#         print(x_pos)\n",
    "        num_=torch.tensor([i.sum() for i in x_pos]) #b*1\n",
    "#         print(num_)\n",
    "        outputs = self.model(x, attention_mask=attention_mask)\n",
    "        y0 = outputs[0] #b*100*768\n",
    "        y1 = outputs[1]\n",
    "        \n",
    "        y_e=[]\n",
    "        for idx,num in enumerate(num_):\n",
    "            if num!=0:\n",
    "#                 print(x_pos[idx].view(1,100),y0[idx].view(100,768))\n",
    "                y_e.append(torch.mm((x_pos[idx].float().view(1,100)),(y0[idx].view(100,768)))/num)\n",
    "            else:\n",
    "                y_e.append(y1[idx].view(1,768))\n",
    "\n",
    "        y_ee=torch.stack(y_e).view(-1,768)\n",
    "#         print(y_ee.shape)\n",
    "        \n",
    "        return self.l1(y_ee)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-chinese were not used when initializing BertModel: ['cls.seq_relationship.weight', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "# ban='_1637317433.7353098_1_0.6902_0.7111'\n",
    "\n",
    "if ban==0:\n",
    "    cls = fn2_cls(device0)\n",
    "else:\n",
    "    cls=torch.load(\"../data/cls\"+str(ban)+\".model\",map_location=device0)\n",
    "\n",
    "sigmoid = nn.Sigmoid()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "418it [00:15, 26.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.03      0.51      0.05       164\n",
      "         1.0       0.98      0.56      0.71      6516\n",
      "\n",
      "    accuracy                           0.56      6680\n",
      "   macro avg       0.50      0.53      0.38      6680\n",
      "weighted avg       0.96      0.56      0.69      6680\n",
      "\n",
      "准确率: 0.5562874251497006\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.5562874251497006, 290.03460693359375)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "def test(device_test):\n",
    "    cls.to(device_test)\n",
    "    cls.eval()\n",
    "\n",
    "    ii=0\n",
    "    epoch_loss=0\n",
    "    for batch_idx,batch in tqdm(enumerate(test_loader)):\n",
    "        with torch.no_grad():\n",
    "            label=batch['label'].to(device_test).float().view(-1,1)\n",
    "            input_ids=torch.stack(batch['input_ids']).t().to(device_test)\n",
    "            mask=torch.stack(batch['mask']).t().to(device_test)\n",
    "\n",
    "            output = cls(input_ids, attention_mask=mask)\n",
    "            output=sigmoid(output)\n",
    "            #计算loss\n",
    "            loss = criterion(output, label)\n",
    "            epoch_loss+=loss\n",
    "            #计算输出\n",
    "            output=output.round()\n",
    "            if ii==0:\n",
    "                all_output=output.view(1,-1)\n",
    "                all_label=label.view(1,-1)\n",
    "                ii=1\n",
    "            else:\n",
    "#                 print(all_output,output)\n",
    "                all_output=torch.cat((all_output,output.view(1,-1)),1)\n",
    "                all_label=torch.cat((all_label,label.view(1,-1)),1)\n",
    "        \n",
    "    all_output=np.array(all_output.t().cpu())\n",
    "    all_label=np.array(all_label.t().cpu())\n",
    "#     can't convert cuda:5 device type tensor to numpy. Use Tensor.cpu() to copy the tensor to host memory first.\n",
    "    acc_score=metrics.accuracy_score(all_output, all_label)\n",
    "    print(metrics.classification_report(all_output, all_label))\n",
    "    print(\"准确率:\",acc_score )\n",
    "    \n",
    "    return acc_score,epoch_loss.item()\n",
    "\n",
    "test(device1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# t_score,t_acc=test()\n",
    "# import torch\n",
    "# torch.save(cls,\"../data/cls_\"+str(ban)+\"_\"+str(round(t_score,4))+\".model\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cls = fn2_cls(device0)\n",
    "from torch import optim\n",
    "optimizer = optim.Adam(cls.parameters(), lr=1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time  # 引入time模块\n",
    "\n",
    "import torch\n",
    "\n",
    "def train(device_train,device_test,epoch_num,epoch_be=0):\n",
    "    for epoch_idx in range(epoch_be,epoch_be+epoch_num):\n",
    "        epoch_loss=0\n",
    "        cls.to(device_train)\n",
    "        cls.train()\n",
    "        ii=0\n",
    "        print(\"_________________________________________________________________\")\n",
    "        print(\"_________________________________________________________________\")\n",
    "        print(\"_________________ epoch:\"+str(epoch_idx)+\" start _________________\")\n",
    "        print(\"_________________________________________________________________\")\n",
    "        print(\"_________________________________________________________________\")\n",
    "\n",
    "        start = time.time()\n",
    "        \n",
    "        for batch_idx,batch in enumerate(train_loader):\n",
    "            print(batch_idx,len(train_loader),batch_idx/len(train_loader),'epoch_loss:',epoch_loss,end= \"\\r\")\n",
    "            \n",
    "            label=batch['label'].to(device_train).float().view(-1,1)\n",
    "            input_ids=torch.stack(batch['input_ids']).t().to(device_train)\n",
    "            mask=torch.stack(batch['mask']).t().to(device_train)\n",
    "\n",
    "            output = cls(input_ids, attention_mask=mask)\n",
    "            output=sigmoid(output)\n",
    "#             print(output)\n",
    "            \n",
    "            # 梯度积累\n",
    "            loss = criterion(output, label)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            #计算score\n",
    "            with torch.no_grad():\n",
    "                epoch_loss+=loss\n",
    "#                 print(output.tolist())\n",
    "                output=output.round()\n",
    "#                 print(output.tolist())\n",
    "#                 print(label.tolist())\n",
    "                if ii==0:\n",
    "                    all_output=output.view(1,-1)\n",
    "                    all_label=label.view(1,-1)\n",
    "                    ii=1\n",
    "                else:\n",
    "#                 \n",
    "                    all_output=torch.cat((all_output,output.view(1,-1)),1)\n",
    "                    all_label=torch.cat((all_label,label.view(1,-1)),1)\n",
    "#                 print(all_output,all_label)\n",
    "\n",
    "        #每个epoch结束：\n",
    "        with torch.no_grad():\n",
    "            all_output=np.array(all_output.t().cpu())\n",
    "            all_label=np.array(all_label.t().cpu())\n",
    "        #     can't convert cuda:5 device type tensor to numpy. Use Tensor.cpu() to copy the tensor to host memory first.\n",
    "            acc_score=metrics.accuracy_score(all_output, all_label)\n",
    "            print(metrics.classification_report(all_output, all_label))\n",
    "            print(\"准确率:\",acc_score)\n",
    "        \n",
    "        acc_score_test,epoch_loss_test=test(device_test)\n",
    "        \n",
    "        print('acc_score:',acc_score,'epoch_loss:',epoch_loss,'acc_score_test:',acc_score_test,'epoch_loss_test:',epoch_loss_test)\n",
    "        #保存模型\n",
    "        end = time.time()\n",
    "        print('epoch:',str(epoch_idx)+'_执行时间: ',end - start)\n",
    "#         torch.save(cls,\"../data/cls_\"+str(end)+\"_\"+str(epoch_idx)+\"_\"+str(round(acc_score,4))+\"_\"+str(round(acc_score_test,4))+\".model\")\n",
    "\n",
    "\n",
    "        print(\"_________________________________________________________________\")\n",
    "        print(\"_________________________________________________________________\")\n",
    "        print(\"_________________ epoch:\"+str(epoch_idx)+\" end _________________\")\n",
    "        print(\"_________________________________________________________________\")\n",
    "        print(\"_________________________________________________________________\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "_________________ epoch:0 start _________________\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "13 1882 0.006907545164718385 epoch_loss: tensor(2.8605, device='cuda:5')\r"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_3300/3415387392.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;31m# optimizer = optim.Adam(cls.parameters(), lr=1e-5)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;31m# test(device1)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdevice1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mepoch_num\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mepoch_be\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/tmp/ipykernel_3300/3789732234.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(device_train, device_test, epoch_num, epoch_be)\u001b[0m\n\u001b[1;32m     31\u001b[0m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m             \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/data/fuwen/anaconda3/envs/bs0/lib/python3.7/site-packages/torch/optim/optimizer.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     86\u001b[0m                 \u001b[0mprofile_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"Optimizer.step#{}.step\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprofiler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecord_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprofile_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 88\u001b[0;31m                     \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     89\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/data/fuwen/anaconda3/envs/bs0/lib/python3.7/site-packages/torch/autograd/grad_mode.py\u001b[0m in \u001b[0;36mdecorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/data/fuwen/anaconda3/envs/bs0/lib/python3.7/site-packages/torch/optim/adam.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m    142\u001b[0m                    \u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgroup\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'lr'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    143\u001b[0m                    \u001b[0mweight_decay\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgroup\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'weight_decay'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 144\u001b[0;31m                    eps=group['eps'])\n\u001b[0m\u001b[1;32m    145\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/data/fuwen/anaconda3/envs/bs0/lib/python3.7/site-packages/torch/optim/_functional.py\u001b[0m in \u001b[0;36madam\u001b[0;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, amsgrad, beta1, beta2, lr, weight_decay, eps)\u001b[0m\n\u001b[1;32m     92\u001b[0m             \u001b[0mdenom\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mmax_exp_avg_sqs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbias_correction2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0meps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 94\u001b[0;31m             \u001b[0mdenom\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mexp_avg_sq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbias_correction2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0meps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     95\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m         \u001b[0mstep_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlr\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mbias_correction1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# zero=0\n",
    "# one=0\n",
    "# for i in range(len(df_train)): \n",
    "#     if df_train.loc[i]['label']==1:\n",
    "#         one+=1\n",
    "#     else:\n",
    "#         zero+=1\n",
    "    \n",
    "# weight = torch.tensor([one/(one+zero)]).to(device1)\n",
    "# print(weight)\n",
    "criterion = nn.BCELoss()#weight=weight\n",
    "# criterion = nn.MSELoss()\n",
    "\n",
    "cls = fn2_cls(device0)\n",
    "from torch import optim\n",
    "optimizer = optim.Adam(cls.parameters(), lr=1e-5)\n",
    "test(device1)\n",
    "train(device0,device1,epoch_num=2,epoch_be=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import torch\n",
    "# end = time.time()\n",
    "# torch.save(cls,\"../data/cls_\"+str(end)+\"_\"+str(0)+\"_\"+str(0.6771)+\"_\"+str(0.7125)+\".model\")\n",
    "\n",
    "# torch.save(cls,\"../data/cls\"+str(ban+50)+\".model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenizer = AutoTokenizer.from_pretrained(\"bert-base-chinese\")\n",
    "\n",
    "def get_output(text,device):\n",
    "        cls.to(device)\n",
    "        cls.eval\n",
    "        text2id = tokenizer(\n",
    "            text, max_length=100, padding='max_length', truncation=True, return_tensors=\"pt\"\n",
    "        )\n",
    "        input_ids=text2id[\"input_ids\"].to(device)\n",
    "        mask=text2id[\"attention_mask\"].to(device)\n",
    "        with torch.no_grad():\n",
    "            output = cls(input_ids, attention_mask=mask)\n",
    "            output1=sigmoid(output)\n",
    "        return output1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.6372],\n",
      "        [0.0170],\n",
      "        [0.9990],\n",
      "        [0.9925],\n",
      "        [0.3425]], device='cuda:5')\n"
     ]
    }
   ],
   "source": [
    "text = ['##char##与n3：啊？',\n",
    "        '##char##一手拿着一个行李，一路小跑着把c1带到了文工团门口',\n",
    "        '##char##开心地点了点头。',\n",
    "        '##char##笑了笑：军礼不是这么敬的。五指并拢，大臂带动小臂，举到齐眉。'\n",
    "       '##char##看到o2拎着行李进来，往他那边走：哟，o2回来了，欢迎我们全军的学雷锋标兵凯旋归来啊！',\n",
    "        'd1看到##char##拎着行李进来，往他那边走：哟，##char##回来了，欢迎我们全军的学雷锋标兵凯旋归来啊！',\n",
    "        \n",
    "       ]\n",
    "# 爱、乐、惊、怒、恐、哀\n",
    "print(get_output(text,device1))#是否含有情感"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bs0",
   "language": "python",
   "name": "bs0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
