{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "ban=0\n",
    "batch_size=4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "device0 = torch.device('cuda:5' if torch.cuda.is_available() else \"cpu\")\n",
    "device1 = torch.device('cuda:5' if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 读数据\n",
    "import pandas as pd\n",
    "df_train=pd.read_excel(\"../data/df_train.xlsx\",index_col=0)\n",
    "df_test=pd.read_excel(\"../data/df_test.xlsx\",index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\n",
    "label18=[]\n",
    "for i in range(len(df_train)):\n",
    "    new_list=[]\n",
    "    old_list=ast.literal_eval(df_train.loc[i]['label'])\n",
    "    df_train.loc[i]['label']=old_list\n",
    "    for j in old_list:\n",
    "        if j==0:\n",
    "            new_list+=[0,0,0]\n",
    "        if j==1:\n",
    "            new_list+=[0,0,1]\n",
    "        if j==2:\n",
    "            new_list+=[0,1,1]\n",
    "        if j==3:\n",
    "            new_list+=[1,1,1]\n",
    "    label18.append(new_list)\n",
    "\n",
    "df_train['label18']=label18"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "label18=[]\n",
    "for i in range(len(df_test)):\n",
    "    new_list=[]\n",
    "    old_list=ast.literal_eval(df_test.loc[i]['label'])\n",
    "    df_test.loc[i]['label']=old_list\n",
    "    for j in old_list:\n",
    "        if j==0:\n",
    "            new_list+=[0,0,0]\n",
    "        if j==1:\n",
    "            new_list+=[0,0,1]\n",
    "        if j==2:\n",
    "            new_list+=[0,1,1]\n",
    "        if j==3:\n",
    "            new_list+=[1,1,1]\n",
    "    label18.append(new_list)\n",
    "\n",
    "df_test['label18']=label18"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModel\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-chinese\")\n",
    "df_train_text=[df_train['text'][i] for i in range(len(df_train))]\n",
    "df_test_text=[df_test['text'][i] for i in range(len(df_test))]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "text2id_train = tokenizer(\n",
    "        df_train_text, max_length=100, padding='max_length', truncation=True, return_tensors=\"pt\"\n",
    "    )\n",
    "input_ids_train=text2id_train[\"input_ids\"]\n",
    "mask_train=text2id_train[\"attention_mask\"]\n",
    "\n",
    "text2id_test = tokenizer(\n",
    "        df_test_text, max_length=100, padding='max_length', truncation=True, return_tensors=\"pt\"\n",
    "    )\n",
    "input_ids_test=text2id_test[\"input_ids\"]\n",
    "mask_test=text2id_test[\"attention_mask\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['input_ids']=input_ids_train.tolist()\n",
    "df_train['mask']=mask_train.tolist()\n",
    "\n",
    "df_test['input_ids']=input_ids_test.tolist()\n",
    "df_test['mask']=mask_test.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_att(input_ids_train_):\n",
    "    index=0\n",
    "    _115=[]\n",
    "    for i in input_ids_train_:\n",
    "        if i==115:\n",
    "#             print(i)\n",
    "            _115.append(index)\n",
    "        index+=1\n",
    "#     print('_115:',_115)\n",
    "    ###########################################################\n",
    "                \n",
    "    if len(_115)==0:\n",
    "        att=[]\n",
    "        num_=0\n",
    "        for i in input_ids_train_:\n",
    "            if i in [101,102,0]:\n",
    "                att.append(0)\n",
    "            else:\n",
    "                att.append(1)\n",
    "                num_+=1\n",
    "        return att,num_\n",
    "    \n",
    "    \n",
    "    ###########################################################\n",
    "    \n",
    "    \n",
    "    att=[]\n",
    "\n",
    "    index=0\n",
    "    max_=0\n",
    "    for i in input_ids_train_:\n",
    "        if i in [101,102,0]:\n",
    "            att.append(-1)\n",
    "            index+=1\n",
    "            continue\n",
    "        att_t=[]\n",
    "        for j in _115:\n",
    "            att_t.append(abs(index-j))\n",
    "\n",
    "        att.append(min(att_t))\n",
    "        if min(att_t)>max_:\n",
    "            max_=min(att_t)\n",
    "        index+=1\n",
    "        \n",
    "#     print('att:',att)\n",
    "    \n",
    "    ###########################################################\n",
    "    att0=[]\n",
    "    sum_=0\n",
    "    num_=0\n",
    "    for j in att:\n",
    "        if j==-1:\n",
    "            att0.append(0)\n",
    "        else:\n",
    "            att0.append(max_-j)\n",
    "            sum_+=max_-j\n",
    "            num_+=1\n",
    "    att1=[]\n",
    "    sum_=sum_/num_\n",
    "    for j in att0:\n",
    "        att1.append(j/sum_)\n",
    "        \n",
    "#     print('att1:',att1)\n",
    "    return att1,num_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "input_ids_train_att=[]\n",
    "input_ids_train_num=[]\n",
    "\n",
    "\n",
    "for i in range(len(input_ids_train)):\n",
    "    att_=get_att(input_ids_train[i])\n",
    "    input_ids_train_att.append(att_[0])\n",
    "    input_ids_train_num.append(att_[1])\n",
    "    \n",
    "input_ids_test_att=[]\n",
    "input_ids_test_num=[]\n",
    "\n",
    "for i in range(len(input_ids_test)):\n",
    "    att_=get_att(input_ids_test[i])\n",
    "    input_ids_test_att.append(att_[0])\n",
    "    input_ids_test_num.append(att_[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['att']=input_ids_train_att\n",
    "df_test['att']=input_ids_test_att\n",
    "\n",
    "df_train['num']=input_ids_train_num\n",
    "df_test['num']=input_ids_test_num\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "class SentimentDataset(Dataset):\n",
    "    def __init__(self,df):\n",
    "        self.dataset = df\n",
    "    def __len__(self):\n",
    "        return len(self.dataset)\n",
    "    def __getitem__(self, idx):\n",
    "        text = self.dataset.loc[idx, \"text\"]\n",
    "        label = self.dataset.loc[idx, \"label\"]\n",
    "#         print(label)\n",
    "        input_ids = self.dataset.loc[idx, \"input_ids\"]\n",
    "        mask = self.dataset.loc[idx, \"mask\"]\n",
    "        label18=self.dataset.loc[idx, \"label18\"]\n",
    "        att=self.dataset.loc[idx, \"att\"]\n",
    "        num=self.dataset.loc[idx, \"num\"]\n",
    "        \n",
    "        sample = {\"text\": text, \"label\": label,\"label18\": label18,\"input_ids\":input_ids,\"mask\":mask,'att':att,'num':num}\n",
    "        # print(sample)\n",
    "        return sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#按batch_size分\n",
    "from torch.utils.data import DataLoader,TensorDataset\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    SentimentDataset(df_train), \n",
    "    batch_size=batch_size, \n",
    "    shuffle=True, \n",
    "    num_workers=0\n",
    ")\n",
    "print(train_loader)\n",
    "\n",
    "test_loader = DataLoader(\n",
    "    SentimentDataset(df_test), \n",
    "    batch_size=batch_size, \n",
    "    shuffle=False, \n",
    "    num_workers=0\n",
    ")\n",
    "print(test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModel\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "class fn_cls(nn.Module):\n",
    "    def __init__(self,device):\n",
    "        super(fn_cls, self).__init__()\n",
    "        self.model = AutoModel.from_pretrained(\"bert-base-chinese\")\n",
    "        self.model.to(device)\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "        self.l1 = nn.Linear(768, 18)\n",
    "\n",
    "    def forward(self, x, att, num ,attention_mask=None):\n",
    "        #att:batch size*100\n",
    "        outputs = self.model(x, attention_mask=attention_mask)\n",
    "        x = outputs[0]#batch size*100*768\n",
    "        \n",
    "        \n",
    "        #100*768    and   100 ---->>>>   768\n",
    "        all_e=[]\n",
    "        for i in range(len(att)):\n",
    "            bb=att[i]#100\n",
    "            aa=x[i]#100*768\n",
    "            cc=aa*bb.view(100,1)\n",
    "            all_e.append(torch.sum(cc,0)/num[i])#1*768\n",
    "            \n",
    "        x=torch.stack(all_e)#batch size*768\n",
    "        \n",
    "        x = self.dropout(x)\n",
    "        x = self.l1(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sigmoid = nn.Sigmoid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "ban='_1636974376.1919332_1_0.7001_0.6911'\n",
    "\n",
    "if ban==0:\n",
    "    cls = fn_cls(device0)\n",
    "#     cls.train()\n",
    "else:\n",
    "    cls=torch.load(\"../data/cls\"+str(ban)+\".model\",map_location=device0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _18to6_(output,round_=0):#18tensor 变 6list\n",
    "    output0=[]\n",
    "    for j in output:#18\n",
    "        i=0\n",
    "        s=''\n",
    "        list6=[]\n",
    "        while(i<len(j)):\n",
    "            ok=j[i]*1.2+j[i+1]*1.1+j[i+2]*1\n",
    "            if round_==1:\n",
    "                list6.append(ok.round().int().tolist())\n",
    "            else:\n",
    "                list6.append(ok.tolist())\n",
    "            i+=3\n",
    "        output0.append(list6)\n",
    "    return output0\n",
    "\n",
    "def get_loss_test(output,A,round_=0):#8*18\n",
    "    output_r=torch.Tensor(_18to6_(output,round_=1)).to(device0)\n",
    "    output=_18to6_(output,round_=round_)\n",
    "    # print(output_r,A)\n",
    "    cor_add=(output_r == A).sum().item()\n",
    "    sum0=0\n",
    "    for i in range(len(output)):\n",
    "        for j in range(6):\n",
    "            sum0+=(output[i][j]-A[i][j])*(output[i][j]-A[i][j])\n",
    "    return sum0,cor_add\n",
    "\n",
    "def test(device_test):\n",
    "    cls.to(device_test)\n",
    "    cls.eval()\n",
    "\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    loss_test=0\n",
    "    for batch_idx,batch in enumerate(test_loader):\n",
    "        with torch.no_grad():\n",
    "#             print(batch['att'])\n",
    "            # print(batch['label'],batch['label18'])\n",
    "            label6=torch.stack(batch['label']).t().to(device_test).float()\n",
    "            # label18=torch.stack(batch['label18']).t().to(device_test).float()\n",
    "\n",
    "            input_ids=torch.stack(batch['input_ids']).t().to(device_test)\n",
    "            mask=torch.stack(batch['mask']).t().to(device_test)\n",
    "            att=torch.stack(batch['att']).t().to(device_test).float()\n",
    "#             print(batch['num'])\n",
    "            num=torch.tensor(batch['num']).t().to(device_test).float()\n",
    "            \n",
    "            output = cls(input_ids, att,num,attention_mask=mask)\n",
    "            output=sigmoid(output)\n",
    "\n",
    "            total += len(output)*6\n",
    "            loss_add,cor_add = get_loss_test(output, label6 ,round_=0)\n",
    "            loss_test+=loss_add\n",
    "            correct+=cor_add\n",
    "\n",
    "            tes_score=1/(1+(loss_test/total) ** 0.5)\n",
    "            acc_score=100.*correct/total\n",
    "\n",
    "        \n",
    "\n",
    "        print('[{}/{} ({:.0f}%)]\\t正确分类的样本数：{}，样本总数：{}，准确率：{:.2f}%，score：{}'.format(\n",
    "                    batch_idx, len(test_loader),100.*batch_idx/len(test_loader), \n",
    "                    correct, total,acc_score,\n",
    "                    tes_score\n",
    "            ),end='\\r')\n",
    "    print('[{}/{} ({:.0f}%)]\\t正确分类的样本数：{}，样本总数：{}，准确率：{:.2f}%，score：{}'.format(\n",
    "                    batch_idx, len(test_loader),100.*batch_idx/len(test_loader), \n",
    "                    correct, total,acc_score,\n",
    "                    tes_score\n",
    "            ))\n",
    "#     cls.to(device_train)\n",
    "    return tes_score,acc_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/fuwen/anaconda3/envs/bs0/lib/python3.7/site-packages/ipykernel_launcher.py:46: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1669/1670 (100%)]\t正确分类的样本数：911，样本总数：40080，准确率：2.27%，score：0.35987967252731323\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(tensor(0.3599, device='cuda:5'), 2.2729540918163673)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test(device1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24585.0\n",
      "[408.0, 722.0, 1132.0, 221.0, 646.0, 1868.0, 280.0, 752.0, 1566.0, 544.0, 1589.0, 2994.0, 378.0, 1202.0, 2130.0, 932.0, 2638.0, 4583.0]\n"
     ]
    }
   ],
   "source": [
    "weight=[]\n",
    "import numpy as np\n",
    "sumn=np.zeros(18)\n",
    "for i in range(len(df_train)):\n",
    "    print(i,end='\\r')\n",
    "    sumn+=np.array(df_train.loc[i]['label18'])\n",
    "#     print(sumn,end='\\r')\n",
    "\n",
    "print(sumn.sum())\n",
    "print(sumn.tolist())\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.01659548505186089, 0.029367500508440107, 0.046044335977221885, 0.008989221069757983, 0.02627618466544641, 0.0759812894041082, 0.01138905836892414, 0.030587756762253407, 0.06369737644905431, 0.022127313402481186, 0.0646329062436445, 0.12178157413056742, 0.01537522879804759, 0.048891600569452916, 0.08663819402074435, 0.03790929428513321, 0.10730119991864959, 0.1864144803742119]\n",
      "tensor([0.0166, 0.0294, 0.0460, 0.0090, 0.0263, 0.0760, 0.0114, 0.0306, 0.0637,\n",
      "        0.0221, 0.0646, 0.1218, 0.0154, 0.0489, 0.0866, 0.0379, 0.1073, 0.1864],\n",
      "       device='cuda:5')\n"
     ]
    }
   ],
   "source": [
    "weight=[i/sumn.sum() for i in sumn.tolist()]\n",
    "print(weight)\n",
    "weight=torch.Tensor(weight).to(device0)\n",
    "print(weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import optim\n",
    "#BCEWithLogitsLoss就是把Sigmoid-BCELoss合成一步\n",
    "criterion = nn.BCELoss(weight=weight)\n",
    "criterion_hui=nn.MSELoss()\n",
    "optimizer = optim.Adam(cls.parameters(), lr=1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "_________________ epoch:0 start _________________\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Train Epoch: 0 [0/7526 (0%)]\tscore:0.365729\t准确率：0.00%\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/fuwen/anaconda3/envs/bs0/lib/python3.7/site-packages/ipykernel_launcher.py:36: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "labels: tensor([[0., 0., 0., 0., 0., 0.],.667286\t准确率：88.83%\n",
      "        [0., 0., 0., 2., 0., 0.]], device='cuda:5')\n",
      "pred: tensor([[0.0788, 0.0384, 0.0430, 0.0374, 0.0700, 0.3323],\n",
      "        [0.1040, 0.0445, 0.0636, 0.0923, 0.3192, 0.8678]], device='cuda:5')\n",
      "Train Epoch: 0\tscore:0.667309\t准确率：88.83%\n",
      "[7/1670 (0%)]\t正确分类的样本数：178，样本总数：192，准确率：92.71%，score：0.7873824238777161\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/fuwen/anaconda3/envs/bs0/lib/python3.7/site-packages/ipykernel_launcher.py:46: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1669/1670 (100%)]\t正确分类的样本数：35493，样本总数：40080，准确率：88.56%，score：0.7014865279197693\n",
      "epoch: 0_执行时间:  432.0926606655121\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "_________________ epoch:0 end _________________\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "_________________ epoch:1 start _________________\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "labels: tensor([[0., 0., 0., 0., 0., 0.],.700078\t准确率：90.46%\n",
      "        [0., 0., 0., 0., 0., 0.]], device='cuda:5')\n",
      "pred: tensor([[0.1453, 0.0590, 0.0182, 0.0082, 0.0198, 0.0674],\n",
      "        [0.0225, 0.0356, 0.0576, 0.1749, 0.1996, 0.0997]], device='cuda:5')\n",
      "Train Epoch: 1\tscore:0.700056\t准确率：90.46%\n",
      "[1669/1670 (100%)]\t正确分类的样本数：34853，样本总数：40080，准确率：86.96%，score：0.6911429762840271\n",
      "epoch: 1_执行时间:  429.480459690094\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "_________________ epoch:1 end _________________\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "_________________ epoch:2 start _________________\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "labels: tensor([[0., 0., 0., 0., 0., 0.],.727445\t准确率：91.82%\n",
      "        [0., 0., 0., 0., 0., 1.]], device='cuda:5')\n",
      "pred: tensor([[0.0364, 0.0161, 0.0076, 0.0169, 0.0071, 0.0246],\n",
      "        [0.0277, 0.0377, 0.0563, 0.0803, 0.0792, 0.6879]], device='cuda:5')\n",
      "Train Epoch: 2\tscore:0.727494\t准确率：91.82%\n",
      "[1669/1670 (100%)]\t正确分类的样本数：34639，样本总数：40080，准确率：86.42%，score：0.6865563392639164\n",
      "epoch: 2_执行时间:  430.5350573062897\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "_________________ epoch:2 end _________________\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "_________________ epoch:3 start _________________\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Train Epoch: 3 [1440/7526 (19%)]\tscore:0.760034\t准确率：93.64%\r"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_5186/3811835897.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    105\u001b[0m \u001b[0;31m#     plt.show()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 107\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdevice1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mepoch_be\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/tmp/ipykernel_5186/3811835897.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(device_train, device_test, epoch_be)\u001b[0m\n\u001b[1;32m     36\u001b[0m             \u001b[0mnum\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'num'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m             \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0matt\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnum\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m             \u001b[0moutput\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msigmoid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m             \u001b[0moutput6\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_18to6_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mround_\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/data/fuwen/anaconda3/envs/bs0/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_5186/3316047697.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, att, num, attention_mask)\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0matt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum\u001b[0m \u001b[0;34m,\u001b[0m\u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0;31m#att:batch size*100\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattention_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;31m#batch size*100*768\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/data/fuwen/anaconda3/envs/bs0/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/data/fuwen/anaconda3/envs/bs0/lib/python3.7/site-packages/transformers/models/bert/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1004\u001b[0m             \u001b[0moutput_attentions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_attentions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1005\u001b[0m             \u001b[0moutput_hidden_states\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_hidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1006\u001b[0;31m             \u001b[0mreturn_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreturn_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1007\u001b[0m         )\n\u001b[1;32m   1008\u001b[0m         \u001b[0msequence_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mencoder_outputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/data/fuwen/anaconda3/envs/bs0/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/data/fuwen/anaconda3/envs/bs0/lib/python3.7/site-packages/transformers/models/bert/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    588\u001b[0m                     \u001b[0mencoder_attention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    589\u001b[0m                     \u001b[0mpast_key_value\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 590\u001b[0;31m                     \u001b[0moutput_attentions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    591\u001b[0m                 )\n\u001b[1;32m    592\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/data/fuwen/anaconda3/envs/bs0/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/data/fuwen/anaconda3/envs/bs0/lib/python3.7/site-packages/transformers/models/bert/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[1;32m    473\u001b[0m             \u001b[0mhead_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    474\u001b[0m             \u001b[0moutput_attentions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_attentions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 475\u001b[0;31m             \u001b[0mpast_key_value\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself_attn_past_key_value\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    476\u001b[0m         )\n\u001b[1;32m    477\u001b[0m         \u001b[0mattention_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself_attention_outputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/data/fuwen/anaconda3/envs/bs0/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/data/fuwen/anaconda3/envs/bs0/lib/python3.7/site-packages/transformers/models/bert/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[1;32m    405\u001b[0m             \u001b[0mencoder_attention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    406\u001b[0m             \u001b[0mpast_key_value\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 407\u001b[0;31m             \u001b[0moutput_attentions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    408\u001b[0m         )\n\u001b[1;32m    409\u001b[0m         \u001b[0mattention_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself_outputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/data/fuwen/anaconda3/envs/bs0/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/data/fuwen/anaconda3/envs/bs0/lib/python3.7/site-packages/transformers/models/bert/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[1;32m    326\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    327\u001b[0m         \u001b[0;31m# Normalize the attention scores to probabilities.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 328\u001b[0;31m         \u001b[0mattention_probs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSoftmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mattention_scores\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    329\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    330\u001b[0m         \u001b[0;31m# This is actually dropping out entire tokens to attend to, which might\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import time  # 引入time模块\n",
    " \n",
    "\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def train(device_train,device_test,epoch_be=0):\n",
    "    epoch_num=4\n",
    "    accumulation_steps=32\n",
    "    \n",
    "    train_score=[]\n",
    "    test_score=[]\n",
    "    test_acc=[]\n",
    "\n",
    "    for epoch_idx in range(epoch_be,epoch_be+epoch_num):\n",
    "        cls.to(device_train)\n",
    "        cls.train()\n",
    "        print(\"_________________________________________________________________\")\n",
    "        print(\"_________________________________________________________________\")\n",
    "        print(\"_________________ epoch:\"+str(epoch_idx)+\" start _________________\")\n",
    "        print(\"_________________________________________________________________\")\n",
    "        print(\"_________________________________________________________________\")\n",
    "        score_list=[]\n",
    "        loss_a=0\n",
    "        total=0\n",
    "        correct=0\n",
    "        start = time.time()\n",
    "        for batch_idx,batch in enumerate(train_loader):\n",
    "            label6=torch.stack(batch['label']).t().to(device_test).float()\n",
    "            label18=torch.stack(batch['label18']).t().to(device_test).float()\n",
    "\n",
    "            #计算output\n",
    "            input_ids=torch.stack(batch['input_ids']).t().to(device_train)\n",
    "            mask=torch.stack(batch['mask']).t().to(device_train)\n",
    "            att=torch.stack(batch['att']).t().to(device_train).float()\n",
    "            \n",
    "            num=torch.tensor(batch['num']).t().to(device_train).float()\n",
    "            \n",
    "            output = cls(input_ids, att,num,attention_mask=mask)\n",
    "            output=sigmoid(output)\n",
    "            output6=torch.Tensor(_18to6_(output,round_=0)).to(device_train)\n",
    "\n",
    "\n",
    "            # 梯度积累\n",
    "            loss0 = criterion(output, label18)\n",
    "            lossh=criterion_hui(output6,label6)\n",
    "\n",
    "            loss=loss0+lossh\n",
    "            loss = loss/accumulation_steps\n",
    "            loss.backward()\n",
    "\n",
    "            #计算score\n",
    "            with torch.no_grad():\n",
    "                total += len(output)*6\n",
    "                loss_add,cor_add = get_loss_test(output, label6,round_=0)\n",
    "                loss_a+=loss_add\n",
    "                correct+=cor_add\n",
    "\n",
    "                tr_score=1/(1+(loss_a/total) ** 0.5)\n",
    "                acc_score=100.*correct/total\n",
    "\n",
    "\n",
    "            if((batch_idx+1) % accumulation_steps) == 0:\n",
    "                # 每 accumulation_steps 次更新一下网络中的参数\n",
    "                optimizer.step()\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "            if ((batch_idx+1) % accumulation_steps) == 1:\n",
    "                score_list.append(tr_score)\n",
    "                print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tscore:{:.6f}\\t准确率：{:.2f}%'.format(\n",
    "                    epoch_idx, batch_idx, len(train_loader), \n",
    "                    100.*batch_idx/len(train_loader), tr_score,acc_score\n",
    "                ),end='\\r')\n",
    "\n",
    "        #每个epoch结束：\n",
    "        print('labels:', label6)\n",
    "        print('pred:', output6)\n",
    "#         plt.plot([i for i in range(len(score_list))], score_list)\n",
    "#         plt.show()\n",
    "\n",
    "        print('Train Epoch: {}\\tscore:{:.6f}\\t准确率：{:.2f}%'.format(epoch_idx,tr_score,acc_score))\n",
    "        t_score,t_acc=test(device_test)\n",
    "\n",
    "        train_score.append(tr_score)\n",
    "        test_score.append(t_score)\n",
    "        test_acc.append(t_acc)\n",
    "\n",
    "        #保存模型\n",
    "        end = time.time()\n",
    "        print('epoch:',str(epoch_idx)+'_执行时间: ',end - start)\n",
    "        torch.save(cls,\"../data/cls_\"+str(end)+\"_\"+str(epoch_idx)+\"_\"+str(round(tr_score.tolist(),4))+\"_\"+str(round(t_score.tolist(),4))+\".model\")\n",
    "\n",
    "        print(\"_________________________________________________________________\")\n",
    "        print(\"_________________________________________________________________\")\n",
    "        print(\"_________________ epoch:\"+str(epoch_idx)+\" end _________________\")\n",
    "        print(\"_________________________________________________________________\")\n",
    "        print(\"_________________________________________________________________\")\n",
    "\n",
    "#     plt.plot([i for i in range(len(train_score))], train_score)\n",
    "#     plt.show()             \n",
    "\n",
    "#     plt.plot([i for i in range(len(test_score))], test_score)\n",
    "#     plt.show()\n",
    "\n",
    "#     plt.plot([i for i in range(len(test_acc))], test_acc)\n",
    "#     plt.show()\n",
    "    \n",
    "train(device0,device1,epoch_be=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "end = time.time()\n",
    "torch.save(cls,\"../data/cls_\"+str(end)+\"_\"+str(2)+\"_\"+str(0.6886)+\"_\"+str(0.6942)+\".model\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenizer = AutoTokenizer.from_pretrained(\"bert-base-chinese\")\n",
    "\n",
    "def get_output(device_pre,model,text,f=0):\n",
    "    model.to(device_pre)\n",
    "    model.eval()\n",
    "    text2id = tokenizer(\n",
    "        text, max_length=100, padding='max_length', truncation=True, return_tensors=\"pt\"\n",
    "    )\n",
    "#     print(text,text2id)\n",
    "    input_ids=text2id[\"input_ids\"].to(device_pre)\n",
    "    mask=text2id[\"attention_mask\"].to(device_pre)\n",
    "    \n",
    "    ee=get_att(input_ids[0])\n",
    "    att=torch.tensor([ee[0]]).to(device_pre)\n",
    "    num=torch.tensor([ee[1]]).t().float().to(device_pre)\n",
    "#         print(text2id)\n",
    "    output = model(input_ids,att,num, attention_mask=mask)\n",
    "    \n",
    "    print(output)\n",
    "    output=sigmoid(output)\n",
    "    print(output)\n",
    "    \n",
    "#     output=sigmoid(output)*4\n",
    "    if f==1:\n",
    "        return _18to6_(output,round_=1)\n",
    "    else:\n",
    "        return _18to6_(output,round_=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-6.1423, -5.6087, -4.7380, -5.4072, -4.9765, -2.5038, -4.1149, -2.4246,\n",
      "         -0.6101, -7.1817, -6.8135, -5.9219, -6.2012, -5.4344, -4.0162, -5.3696,\n",
      "         -3.8519, -2.8348]], device='cuda:5', grad_fn=<AddmmBackward0>)\n",
      "tensor([[0.0021, 0.0037, 0.0087, 0.0045, 0.0069, 0.0756, 0.0161, 0.0813, 0.3520,\n",
      "         0.0008, 0.0011, 0.0027, 0.0020, 0.0043, 0.0177, 0.0046, 0.0208, 0.0555]],\n",
      "       device='cuda:5', grad_fn=<SigmoidBackward0>)\n",
      "[[0.015272149816155434, 0.08848606795072556, 0.4607667922973633, 0.004792036488652229, 0.0249085184186697, 0.08390951156616211]]\n"
     ]
    }
   ],
   "source": [
    "text = ['*与n3：啊？']\n",
    "# 爱、乐、惊、怒、恐、哀\n",
    "print(get_output(device1,cls,text,0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bs0",
   "language": "python",
   "name": "bs0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
