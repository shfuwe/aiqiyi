{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "cuda_num = str(0)\n",
    "ban='_1636187797.403441_4_0.6958_0.7013'\n",
    "batch_size=16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 读数据\n",
    "import pandas as pd\n",
    "df_train=pd.read_excel(\"../data/df_train.xlsx\",index_col=0)\n",
    "df_test=pd.read_excel(\"../data/df_test.xlsx\",index_col=0)\n",
    "import ast\n",
    "for i in range(len(df_train)):\n",
    "    df_train.loc[i]['label']=ast.literal_eval(df_train.loc[i]['label'])\n",
    "\n",
    "for i in range(len(df_test)):\n",
    "    df_test.loc[i]['label']=ast.literal_eval(df_test.loc[i]['label'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModel\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-chinese\")\n",
    "df_train_text=[df_train['text'][i] for i in range(len(df_train))]\n",
    "df_test_text=[df_test['text'][i] for i in range(len(df_test))]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "text2id_train = tokenizer(\n",
    "        df_train_text, max_length=100, padding='max_length', truncation=True, return_tensors=\"pt\"\n",
    "    )\n",
    "input_ids_train=text2id_train[\"input_ids\"]\n",
    "mask_train=text2id_train[\"attention_mask\"]\n",
    "df_train['input_ids']=input_ids_train.tolist()\n",
    "df_train['mask']=mask_train.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "text2id_test = tokenizer(\n",
    "        df_test_text, max_length=100, padding='max_length', truncation=True, return_tensors=\"pt\"\n",
    "    )\n",
    "input_ids_test=text2id_test[\"input_ids\"]\n",
    "mask_test=text2id_test[\"attention_mask\"]\n",
    "df_test['input_ids']=input_ids_test.tolist()\n",
    "df_test['mask']=mask_test.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "class SentimentDataset(Dataset):\n",
    "    def __init__(self,df):\n",
    "        self.dataset = df\n",
    "    def __len__(self):\n",
    "        return len(self.dataset)\n",
    "    def __getitem__(self, idx):\n",
    "        text = self.dataset.loc[idx, \"text\"]\n",
    "        label = self.dataset.loc[idx, \"label\"]\n",
    "#         print(label)\n",
    "        input_ids = self.dataset.loc[idx, \"input_ids\"]\n",
    "        mask = self.dataset.loc[idx, \"mask\"]\n",
    "        sample = {\"text\": text, \"label\": label,\"input_ids\":input_ids,\"mask\":mask}\n",
    "        # print(sample)\n",
    "        return sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<torch.utils.data.dataloader.DataLoader object at 0x7f69547d4750>\n",
      "<torch.utils.data.dataloader.DataLoader object at 0x7f67c6152190>\n"
     ]
    }
   ],
   "source": [
    "#按batch_size分\n",
    "from torch.utils.data import DataLoader,TensorDataset\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    SentimentDataset(df_train), \n",
    "    batch_size=batch_size, \n",
    "    shuffle=True, \n",
    "    num_workers=2\n",
    ")\n",
    "print(train_loader)\n",
    "\n",
    "test_loader = DataLoader(\n",
    "    SentimentDataset(df_test), \n",
    "    batch_size=batch_size, \n",
    "    shuffle=False, \n",
    "    num_workers=2\n",
    ")\n",
    "print(test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModel\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "class fn_cls(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(fn_cls, self).__init__()\n",
    "        self.model = AutoModel.from_pretrained(\"bert-base-chinese\")\n",
    "        self.model.to(device)\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "        self.l1 = nn.Linear(768, 6)\n",
    "\n",
    "    def forward(self, x, attention_mask=None):\n",
    "        outputs = self.model(x, attention_mask=attention_mask)\n",
    "#         print(outputs[0])torch.Size([8, 100, 768])\n",
    "#         print(outputs[1])torch.Size([8, 768])\n",
    "#         print(outputs[0][:,0,:])torch.Size([8, 768])\n",
    "#         print(outputs[1])torch.Size([8, 768])\n",
    "        x = outputs[1]\n",
    "        x = self.dropout(x)\n",
    "        x = self.l1(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import optim\n",
    "import torch\n",
    "\n",
    "device_s = \"cuda:\" + cuda_num\n",
    "device = torch.device(device_s if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "if ban==0:\n",
    "    cls = fn_cls()\n",
    "    cls.to(device)\n",
    "    cls.train()\n",
    "else:\n",
    "    cls=torch.load(\"../data/cls\"+str(ban)+\".model\",map_location=device)\n",
    "\n",
    "\n",
    "criterion = nn.MSELoss()\n",
    "sigmoid = nn.Sigmoid()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_loss_test(output,A):#8*6\n",
    "#     print('loss_test')\n",
    "    sum0=0\n",
    "    for i in range(len(output)):\n",
    "        for j in range(6):\n",
    "            sum0+=(output[i][j]-A[i][j])*(output[i][j]-A[i][j])\n",
    "    return sum0\n",
    "\n",
    "def test():\n",
    "    cls.eval()\n",
    "\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    loss_test=0\n",
    "    for batch_idx,batch in enumerate(test_loader):\n",
    "        label=torch.stack(batch['label']).t().to(device).float()\n",
    "        input_ids=torch.stack(batch['input_ids']).t().to(device)\n",
    "        mask=torch.stack(batch['mask']).t().to(device)\n",
    "    \n",
    "        output = cls(input_ids, attention_mask=mask)\n",
    "        output=output.round()\n",
    "        \n",
    "        total += len(output)*6\n",
    "        loss_test += get_loss_test(output.tolist(), label.tolist())\n",
    "        tes_score=1/(1+(loss_test/total) ** 0.5)\n",
    "        \n",
    "        correct += (output == label).sum().item()\n",
    "\n",
    "        \n",
    "\n",
    "        print('[{}/{} ({:.0f}%)]\\t正确分类的样本数：{}，样本总数：{}，准确率：{:.2f}%，score：{}'.format(\n",
    "                    batch_idx, len(test_loader),100.*batch_idx/len(test_loader), \n",
    "                    correct, total,100.*correct/total,\n",
    "                    tes_score\n",
    "            ),end= \"\\r\")\n",
    "    print('[{}/{} ({:.0f}%)]\\t正确分类的样本数：{}，样本总数：{}，准确率：{:.2f}%，score：{}'.format(\n",
    "                    batch_idx, len(test_loader),100.*batch_idx/len(test_loader), \n",
    "                    correct, total,100.*correct/total,\n",
    "                    tes_score\n",
    "            ))\n",
    "    return tes_score,100.*correct/total\n",
    "\n",
    "# test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# t_score,t_acc=test()\n",
    "# import torch\n",
    "# torch.save(cls,\"../data/cls_\"+str(ban)+\"_\"+str(round(t_score,4))+\".model\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(cls.parameters(), lr=1e-6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "_________________ epoch:0 start _________________\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "labels: tensor([[0., 0., 0., 0., 0., 2.],\n",
      "        [0., 0., 0., 0., 0., 0.],\n",
      "        [0., 1., 0., 0., 0., 0.],\n",
      "        [0., 1., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0.]], device='cuda:0')\n",
      "pred: tensor([[ 0.0594, -0.0028,  0.0354,  0.4049,  0.3235,  0.7689],\n",
      "        [-0.0086, -0.0016,  0.1627,  0.3170,  0.1231,  0.3844],\n",
      "        [ 0.0176,  0.7806,  0.0707,  0.0553, -0.0348, -0.0112],\n",
      "        [-0.0703,  0.1896, -0.0091, -0.0724, -0.1072,  0.5039],\n",
      "        [ 0.0619,  0.0505,  0.3450, -0.1001,  0.3185,  0.0194],\n",
      "        [-0.0749, -0.0571, -0.0331,  0.0881, -0.0612, -0.0064]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward0>)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 0\tscore:0.703461\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "[417/418 (100%)]\t正确分类的样本数：34927，样本总数：40080，准确率：87.14%，score：0.6978164920167088\n",
      "epoch: 0_执行时间:  449.75786089897156\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "_________________ epoch:0 end _________________\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "_________________ epoch:1 start _________________\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Train Epoch: 1 [64/1882 (3%)]\tscore:0.703431\r"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_21851/3051907344.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     30\u001b[0m         \u001b[0;31m#计算score\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m         \u001b[0mtotal\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m6\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m         \u001b[0mloss_a\u001b[0m\u001b[0;34m+=\u001b[0m\u001b[0mget_loss_test\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m         \u001b[0mtr_score\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss_a\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mtotal\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m**\u001b[0m \u001b[0;36m0.5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import time  # 引入time模块\n",
    " \n",
    "\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "epoch=10\n",
    "accumulation_steps=32\n",
    "train_score=[]\n",
    "test_score=[]\n",
    "test_acc=[]\n",
    "model_list=[]\n",
    "for epoch_idx in range(epoch):\n",
    "    print(\"_________________________________________________________________\")\n",
    "    print(\"_________________________________________________________________\")\n",
    "    print(\"_________________ epoch:\"+str(epoch_idx)+\" start _________________\")\n",
    "    print(\"_________________________________________________________________\")\n",
    "    print(\"_________________________________________________________________\")\n",
    "    score_list=[]\n",
    "    loss_a=0\n",
    "    total=0\n",
    "    start = time.time()\n",
    "    for batch_idx,batch in enumerate(train_loader):\n",
    "        label=torch.stack(batch['label']).t().to(device).float()\n",
    "        \n",
    "        #计算output\n",
    "        input_ids=torch.stack(batch['input_ids']).t().to(device)\n",
    "        mask=torch.stack(batch['mask']).t().to(device)\n",
    "        output = cls(input_ids, attention_mask=mask)\n",
    "        \n",
    "        #计算score\n",
    "        total += len(output)*6\n",
    "        loss_a+=get_loss_test(output.tolist(), label.tolist())\n",
    "        tr_score=1/(1+(loss_a/total) ** 0.5)\n",
    "        \n",
    "        # 梯度积累\n",
    "        loss = criterion(output, label)\n",
    "        loss = loss/accumulation_steps\n",
    "        loss.backward()\n",
    "\n",
    "        if((batch_idx+1) % accumulation_steps) == 0:\n",
    "            # 每 accumulation_steps 次更新一下网络中的参数\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "        if ((batch_idx+1) % accumulation_steps) == 1:\n",
    "            score_list.append(tr_score)\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tscore:{:.6f}'.format(\n",
    "                epoch_idx, batch_idx, len(train_loader), \n",
    "                100.*batch_idx/len(train_loader), tr_score\n",
    "            ),end = \"\\r\")\n",
    "\n",
    "    #每个epoch结束：\n",
    "    print('labels:', label)\n",
    "    print('pred:', output)\n",
    "    plt.plot([i for i in range(len(score_list))], score_list)\n",
    "    plt.show()\n",
    "    \n",
    "    print('Train Epoch: {}\\tscore:{:.6f}'.format(epoch_idx,tr_score))\n",
    "    t_score,t_acc=test()\n",
    "    \n",
    "    train_score.append(tr_score)\n",
    "    test_score.append(t_score)\n",
    "    test_acc.append(t_acc)\n",
    "    \n",
    "    #保存模型\n",
    "    end = time.time()\n",
    "    print('epoch:',str(epoch_idx)+'_执行时间: ',end - start)\n",
    "    torch.save(cls,\"../data/cls_\"+str(end)+\"_\"+str(epoch_idx)+\"_\"+str(round(tr_score,4))+\"_\"+str(round(t_score,4))+\".model\")\n",
    "    \n",
    "\n",
    "    \n",
    "    \n",
    "    print(\"_________________________________________________________________\")\n",
    "    print(\"_________________________________________________________________\")\n",
    "    print(\"_________________ epoch:\"+str(epoch_idx)+\" end _________________\")\n",
    "    print(\"_________________________________________________________________\")\n",
    "    print(\"_________________________________________________________________\")\n",
    "\n",
    "plt.plot([i for i in range(len(train_score))], train_score)\n",
    "plt.show()             \n",
    "    \n",
    "plt.plot([i for i in range(len(test_score))], test_score)\n",
    "plt.show()\n",
    "\n",
    "plt.plot([i for i in range(len(test_acc))], test_acc)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "end = time.time()\n",
    "torch.save(cls,\"../data/cls_\"+str(end)+\"_\"+str(epoch_idx)+\"_\"+str(round(tr_score,4))+\".model\")\n",
    "\n",
    "# torch.save(cls,\"../data/cls\"+str(ban+50)+\".model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenizer = AutoTokenizer.from_pretrained(\"bert-base-chinese\")\n",
    "\n",
    "def get_output(model,text,f=0):\n",
    "    text2id = tokenizer(\n",
    "        text, max_length=100, padding='max_length', truncation=True, return_tensors=\"pt\"\n",
    "    )\n",
    "#     print(text,text2id)\n",
    "    input_ids=text2id[\"input_ids\"].to(device)\n",
    "    mask=text2id[\"attention_mask\"].to(device)\n",
    "#         print(text2id)\n",
    "    output = model(input_ids, attention_mask=mask)\n",
    "#     output=sigmoid(output)*4\n",
    "    if f==1:\n",
    "        print(output)\n",
    "        output=output.round()\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'cls' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_34086/1196020211.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mtext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'*与n3：啊？'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m# 爱、乐、惊、怒、恐、哀\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mget_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'cls' is not defined"
     ]
    }
   ],
   "source": [
    "text = ['*与n3：啊？']\n",
    "# 爱、乐、惊、怒、恐、哀\n",
    "print(get_output(cls,text,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bs0",
   "language": "python",
   "name": "bs0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
